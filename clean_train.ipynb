{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "# os.environ[\"GPU\"] = \"1\"\n",
    "# os.environ[\"CLANG\"] = \"1\"\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "from tinygrad.tensor import Tensor\n",
    "from tinygrad.nn import optim\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as plt    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self) -> None:\n",
    "        self.l1 = Tensor.glorot_uniform(1, 2)\n",
    "        self.mid = Tensor.glorot_uniform(2, 2)\n",
    "        self.l2 = Tensor.glorot_uniform(2, 1)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = x/3.1415\n",
    "        x = (x.dot(self.l1)).tanh()\n",
    "        x = (x.dot(self.mid)).tanh()\n",
    "        x = (x.dot(self.l2))\n",
    "        return x\n",
    "\n",
    "    def save(self, filename):\n",
    "        with open(filename+'.npz', 'wb') as f:\n",
    "            np.savez(f, *[p.cpu().numpy() for p in optim.get_parameters(self)])\n",
    "\n",
    "    def load(self, filename):\n",
    "        try:\n",
    "            arrays = np.load(filename)\n",
    "            params = [Tensor(arrays[k]) for k in arrays.keys()]\n",
    "            for param, load in zip(optim.get_parameters(self), params):\n",
    "                if param.shape == load.shape:\n",
    "                    param = load\n",
    "                else:\n",
    "                    raise f\"Shape mismatch!  {param.shape} != {load.shape}\"\n",
    "            print(\"successfully loaded\")\n",
    "        except Exception as e:\n",
    "            print(\"failed to load\")\n",
    "            print(e)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        rep = \"\"\n",
    "        for param in optim.get_parameters(self):\n",
    "            rep += f\"{param.shape} {param.flatten().detach().numpy()}\\n\"\n",
    "        return rep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sin_gen():\n",
    "    while True:\n",
    "        x = np.random.random(1)*2*np.pi - np.pi\n",
    "        y = np.sin(x)+ np.random.randn(1)*0.001\n",
    "        yield x, y\n",
    "\n",
    "def sin_eval():\n",
    "    while True:\n",
    "        x = np.random.random(1)*2*np.pi - np.pi\n",
    "        y = np.sin(x)\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the dict\n",
    "x,y = [],[]\n",
    "x__, y__ = [ ], [ ]\n",
    "for i in range(1000):\n",
    "    x_, y_ = next(sin_gen())\n",
    "    x___, y___ = next(sin_eval())\n",
    "    x__.append(x___)\n",
    "    y__.append(y___)\n",
    "    x.append(x_)\n",
    "    y.append(y_)\n",
    "\n",
    "plt.scatter(x, y, label = \"train\", color = \"blue\", alpha=0.5)\n",
    "plt.scatter(x__, y__, label = \"eval\", color = \"red\", alpha=0.5, marker='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_exp_decay(lr0, epoch, decay):\n",
    "    return max(lr0 * np.exp(-decay*epoch),0.00001)\n",
    "\n",
    "# graph\n",
    "lrs = [lr_exp_decay(0.01, i, 0.05) for i in range(50)]\n",
    "plt.plot(lrs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel = Model()\n",
    "save_name = \"sin\"\n",
    "myOptim = optim.Adam(optim.get_parameters(myModel), lr=0.01)\n",
    "\n",
    "def MSE(y, y_):\n",
    "    return ((y - y_)**2).sum()  \n",
    "\n",
    "def MAE(y, y_):\n",
    "    return (y - y_).abs().mean()\n",
    "\n",
    "loss_fxn = MAE\n",
    "# loss_fxn = MSE\n",
    "print(myModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train loop\n",
    "total_preds = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "best = 0\n",
    "patience = 0\n",
    "best_val = np.inf\n",
    "X_train, Y_train = [], []\n",
    "epochs = 2\n",
    "# main loop\n",
    "for e in tqdm.tqdm(range(epochs)):\n",
    "    myOptim.lr = lr_exp_decay(0.03, e, 0.05)\n",
    "    X_train = np.array(X_train, dtype=np.float32)\n",
    "    Y_train = np.array(Y_train, dtype=np.float32)\n",
    "    # train loop\n",
    "    Tensor.training = True\n",
    "    total_loss = 0\n",
    "    for i in range(100):\n",
    "        x, y = next(sin_gen())\n",
    "        x = Tensor(np.array(x,dtype=np.float32), requires_grad=False)\n",
    "        y = Tensor(np.array(y,dtype=np.float32), requires_grad=False)\n",
    "        myOptim.zero_grad()\n",
    "        y_ = myModel(x)[0]\n",
    "        loss = loss_fxn(y, y_)\n",
    "        total_loss += loss.detach().numpy()/100\n",
    "        loss.backward()\n",
    "        myOptim.step()\n",
    "    train_history.append(total_loss)\n",
    "    print(\"Train loss\", total_loss)\n",
    "\n",
    "    # validation loop\n",
    "    Tensor.training = False\n",
    "    total_val_loss = 0\n",
    "    temp=[]\n",
    "    for i in range(100):\n",
    "        x_val, y_val = next(sin_eval())\n",
    "        x_val = Tensor(np.array(x_val,dtype=np.float32), requires_grad=False)\n",
    "        y_val = Tensor(np.array(y_val,dtype=np.float32), requires_grad=False)\n",
    "        y_val_ = myModel(x_val)[0]\n",
    "        temp.append((x_val.numpy(), y_val_.numpy()))\n",
    "        val_loss = loss_fxn(y_val, y_val_)\n",
    "        total_val_loss += val_loss.detach().numpy()/100\n",
    "    val_history.append(total_val_loss)\n",
    "    print(\"Validation loss\", total_val_loss)\n",
    "\n",
    "    if total_val_loss < best_val:\n",
    "        best_val = total_val_loss\n",
    "        myModel.save(save_name)\n",
    "        print(\"-----saved-----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_history, label=\"train\")\n",
    "plt.plot(val_history, label=\"val\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  load the best model\n",
    "myModel.load(f\"{save_name}.npz\")\n",
    "print(myModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distribution of weights per layer\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(len(optim.get_parameters(myModel))):\n",
    "    plt.subplot(len(optim.get_parameters(myModel)),1, i+1)\n",
    "    plt.hist(optim.get_parameters(myModel)[i].detach().numpy().flatten(), label=f\"layer {i}\")\n",
    "    plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  start the codegen process\n",
    "import subprocess\n",
    "#  generate the code DEBUG=5\n",
    "cmd2 = f'CLANG=1 OPT=1 python3 compile.py --name={save_name}'\n",
    "res2 = subprocess.run(cmd2, shell=True, capture_output=True, text=True)\n",
    "print(res2.stdout)\n",
    "C_name = res2.stdout.split(\":\")[-1].strip()\n",
    "print(\"C name is \",C_name)\n",
    "# save as .so\n",
    "so_name = C_name[:-2] + \".so\"\n",
    "print(\"so name is \",so_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_cmd = f'gcc -shared -lm -fPIC -x c -o {so_name} {C_name}' # --rtlib=compiler-rt\n",
    "print(\"COMILING....\\n\",compile_cmd)\n",
    "res3 = subprocess.run(compile_cmd, shell=True, capture_output=True, text=True)\n",
    "if len(res3.stderr) > 0:\n",
    "    print(\"ERROR\", res3.stderr)\n",
    "else:\n",
    "    print(\"SUCCESS\", res3.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctypes\n",
    "my_model = ctypes.CDLL(\"./\"+so_name)\n",
    "my_model.forward.argtypes = [ctypes.c_float]\n",
    "my_model.forward.restype = ctypes.c_float\n",
    "\n",
    "#  test \n",
    "y = my_model.forward(0.5)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  evaluate the model\n",
    "X_eval, Y_eval, Y_pred, C_pred  = [], [], [], []\n",
    "x = np.linspace(-np.pi, np.pi, 50, dtype=np.float32)\n",
    "for i in range(50):\n",
    "    x_, y_ = next(sin_eval())\n",
    "    X_eval.append(x_)\n",
    "    Y_eval.append(y_)\n",
    "    out = myModel(Tensor(np.array(x_, dtype=np.float32), requires_grad=False)).numpy()\n",
    "    Y_pred.append(out)\n",
    "    res = my_model.forward(ctypes.c_float(x[i]))\n",
    "    C_pred.append(res)\n",
    "\n",
    "X_eval = np.array(X_eval, dtype=np.float32)\n",
    "Y_eval = np.array(Y_eval, dtype=np.float32)\n",
    "Y_pred = np.array(Y_pred, dtype=np.float32)\n",
    "C_pred = np.array(C_pred, dtype=np.float32)\n",
    "\n",
    "plt.scatter(X_eval, Y_eval, label = \"eval\", color = \"red\", alpha=0.5, marker='o')\n",
    "plt.scatter(X_eval, Y_pred, label = \"pred\", color = \"blue\", alpha=0.3, marker='x')\n",
    "plt.scatter(x, C_pred, label = \"C\", color = \"green\", alpha=1, marker='+')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
